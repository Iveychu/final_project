knitr::opts_chunk$set(echo = FALSE)
require(readr)
require(tidyverse)
require(reshape)
require(caret)
require(recipes)
require(pdp)
require(vip)
## Data wrangling
data1 = read_csv("age_dependency_ratio.csv") %>%
select("Country Name", "2008":"2017") %>%
gather(Year, age_dependency_ratio, "2008":"2017")
data2 = read_csv("alcohol use disorder and drug use disorder.csv") %>%
select(-"Code", -"Total population (Gapminder)") %>%
filter(Year == "2008"|Year == "2009"|Year == "2010"|Year == "2011"|Year == "2012"|Year == "2013"|Year ==      "2014"|Year == "2015"|Year == "2016"|Year =="2017")
names(data2) <- c("Country Name", "Year", "AUD", "DUD")
data3 = read_csv("GDP.csv") %>%
select(-"Code") %>%
filter(Year == "2008"|Year == "2009"|Year == "2010"|Year == "2011"|Year == "2012"|Year == "2013"|Year ==      "2014"|Year == "2015"|Year == "2016"|Year =="2017")
names(data3) <- c("Country Name", "Year", "GDP")
data4 = read_csv("GNI.csv") %>%
select("Country Name", "2008":"2017") %>%
gather(Year, GNI, "2008":"2017" )
data5 = read_csv("labor force.csv") %>%
select("Country Name", "2008":"2017") %>%
gather(Year, labor_force, "2008":"2017")
data6 = read_csv("primary school enrollment.csv") %>%
select("Country Name", "2008":"2017") %>%
gather(Year, primary_school_enrollment, "2008":"2017")
data7 = read_csv("refugee population.csv") %>%
select("Country Name", "2008":"2017") %>%
gather(Year, refugee_population, "2008":"2017")
data8 = read_csv("unemployment.csv") %>%
select("Country Name", "2008":"2017") %>%
gather(Year, unemployment, "2008":"2017")
data9 = read_csv("population.csv") %>%
select("Country Name", "2008":"2017") %>%
gather(Year, population, "2008":"2017")
data10 = read_csv("population_male.csv") %>%
select("Country Name", "2008":"2017") %>%
gather(Year, population_male, "2008":"2017")
data11 = read_csv("population_female.csv") %>%
select("Country Name", "2008":"2017") %>%
gather(Year, population_female, "2008":"2017")
data_ml <- Reduce(function(old, new) { merge(old, new, by=c('Country Name', 'Year'), all = TRUE)},
list(data1, data2, data3, data4, data5, data6, data7,
data8, data9, data10, data11)) %>%
mutate(sexratio = population_male / population_female) %>%
na.omit(data_ml)
head(data_ml)
#split the data
index = createDataPartition(data_ml$AUD,p=.75,list=F)
train_data1 = data_ml[index,] # Use 75% of the data as training data
test_data1 = data_ml[-index,] # holdout 25% as test data
dim(train_data1)
dim(test_data1)
skimr::skim(train_data1)
#visualize the distribution for each variable
train_data1 %>%
select_if(is.numeric) %>%
gather(var,val) %>%
ggplot(aes(val,group=var)) +
geom_histogram(bins = 30) +
facet_wrap(~var,scales="free",ncol=2)
#visualize the correlation
sigma = train_data1 %>% select(age_dependency_ratio, AUD, DUD, GDP, sexratio, primary_school_enrollment, refugee_population, unemployment) %>% cor()
ggcorrplot::ggcorrplot(sigma,hc.order = TRUE,outline.col = "white",tl.cex = 5)
data_pred <-
data_ml %>%
select(age_dependency_ratio, AUD, DUD, GDP, GNI, labor_force, population, sexratio, primary_school_enrollment, refugee_population, unemployment )
summarise(data_pred)
# Generate our recipe to preprocess the data
rcp <-
recipe(AUD~.,data = data_pred) %>%
step_range(all_numeric()) %>%  # Normalize scale
prep()
# Apply the recipe to the training and test data
train_data2 <- bake(rcp,new_data = data_pred)
test_data2 <- bake(rcp,new_data = data_pred)
# Cross-validation
set.seed(1988) # set a seed for replication purposes
folds <- createFolds(train_data2$AUD, k = 10) # Partition the data into 10 equal folds
sapply(folds,length)
#set up our validation conditions
control_conditions <-
trainControl(method='cv', # K-fold cross validation
index = folds # The indices for our folds (so they are always the same)
)
# Linear Regression
mod_lm <-
train(AUD ~ .,          # Equation (outcome and everything else)
data=train_data2, # Training data
method = "lm",    # linear model
metric = "RMSE",   # mean squared error
trControl = control_conditions # Cross validation conditions
)
mod_lm
# K-Nearest Neighbors
mod_knn <-
train(AUD ~ .,           # Equation (outcome and everything else)
data=train_data2,  # Training data
method = "knn",    # K-Nearest Neighbors Algorithm
metric = "RMSE",   # mean squared error
trControl = control_conditions # Cross validation conditions
)
mod_knn
plot(mod_knn)
# Random Forest
mod_rf <-
train(AUD ~ ., # Equation (outcome and everything else)
data=train_data2, # Training data
method = "ranger", # random forest (ranger is much faster than rf)
metric = "RMSE",     # mean squared error
trControl = control_conditions,
importance = 'impurity'
)
mod_rf
plot(mod_rf)
# Model Comparison
# Organize all model imputs as a list.
mod_list <-
list(
lm = mod_lm,
knn = mod_knn,
rf = mod_rf
)
# Resamples allows us to compare model output
resamples(mod_list)
dotplot(resamples(mod_list),metric = "RMSE") #Examine the error across each of the models.
dotplot(resamples(mod_list),metric = "Rsquared")
#Test the Predictive Accuracy of the Best Model
pred <- predict(mod_rf,newdata = test_data2)
mse = sum(test_data2$AUD-pred^2)/nrow(test_data2)
mse
plot(varImp(mod_rf,scale=T),top = 10)
# Linear Regression
mod_lm <-
train(AUD ~ .,          # Equation (outcome and everything else)
data=train_data2, # Training data
method = "lm",    # linear model
metric = "RMSE",   # mean squared error
trControl = control_conditions # Cross validation conditions
)
mod_lm
plot(mod_lm)
# Linear Regression
mod_lm <-
train(AUD ~ .,          # Equation (outcome and everything else)
data=train_data2, # Training data
method = "lm",    # linear model
metric = "RMSE",   # mean squared error
trControl = control_conditions # Cross validation conditions
)
mod_lm
pred_lm <- predict(mod_lm, test_data2)
pred_lm <- data.frame(pred = pred_lm, sexratio = test_data2$sexratio)
# Linear Regression
mod_lm <-
train(AUD ~ .,          # Equation (outcome and everything else)
data=train_data2, # Training data
method = "lm",    # linear model
metric = "RMSE",   # mean squared error
trControl = control_conditions # Cross validation conditions
)
mod_lm
pred_lm <- predict(mod_lm, test_data2)
pred_lm <- data.frame(pred = pred_lm, sexratio = test_data2$sexratio)
pred_lm
# Linear Regression
mod_lm <-
train(AUD ~ .,          # Equation (outcome and everything else)
data=train_data2, # Training data
method = "lm",    # linear model
metric = "RMSE",   # mean squared error
trControl = control_conditions # Cross validation conditions
)
mod_lm
pred_lm <- predict(mod_lm, test_data2)
pred_lm <- data.frame(pred = pred_lm, sexratio = test_data2$sexratio)
require(ggplot2)
ggplot(data = pred_lm) + geom_line(aes(x = sexratio, y = pred)) + geom_point(data = test_data2, aes(x=sexratio, y=pred))
# Linear Regression
mod_lm <-
train(AUD ~ .,          # Equation (outcome and everything else)
data=train_data2, # Training data
method = "lm",    # linear model
metric = "RMSE",   # mean squared error
trControl = control_conditions # Cross validation conditions
)
mod_lm
pred_lm <- predict(mod_lm, test_data2)
pred_lm <- data.frame(pred = pred_lm, sexratio = test_data2$sexratio)
require(ggplot2)
ggplot(data = pred_lm) + geom_line(aes(x = sexratio, y = pred)) + geom_point(data = test_data2, aes(x=sexratio, y=pred))
# Linear Regression
mod_lm <-
train(AUD ~ .,          # Equation (outcome and everything else)
data=train_data2, # Training data
method = "lm",    # linear model
metric = "RMSE",   # mean squared error
trControl = control_conditions # Cross validation conditions
)
mod_lm
pred_lm <- predict(mod_lm, test_data2)
pred_lm <- data.frame(pred = pred_lm, sexratio = test_data2$sexratio)
require(ggplot2)
ggplot(data = pred_lm) + geom_line(aes(x = sexratio, y = pred)) + geom_point(data = test_data2, aes(x=sexratio, y=pred))
require(ggplot2)
ggplot(data = pred_lm) + geom_line(aes(x = sexratio, y = pred)) + geom_point(data = test_data2, aes(x=sexratio, y=pred))
require(readr)
require(tidyverse)
require(reshape)
require(caret)
require(recipes)
require(pdp)
require(vip)
require(ggplot2)
ggplot(data = pred_lm) + geom_line(aes(x = sexratio, y = pred)) + geom_point(data = test_data2, aes(x=sexratio, y=pred))
# ggplot(data = pred_lm) + geom_line(aes(x = sexratio, y = pred)) + geom_point(data = test_data2, aes(x=sexratio, y=pred))
test_data2
ggplot(data = pred_lm) + geom_line(aes(x = sexratio, y = pred)) + geom_point(data = test_data2, aes(x=sexratio, y=AUD))
plot(mod_knn)
# Random Forest
mod_rf <-
train(AUD ~ ., # Equation (outcome and everything else)
data=train_data2, # Training data
method = "ranger", # random forest (ranger is much faster than rf)
metric = "RMSE",     # mean squared error
trControl = control_conditions,
importance = 'impurity'
)
mod_rf
plot(mod_rf)
dotplot(resamples(mod_list),metric = "RMSE")
dotplot(resamples(mod_list),metric = "Rsquared")
plot(varImp(mod_rf,scale=T),top = 10)
#Test the Predictive Accuracy of the Best Model
pred <- predict(mod_rf,newdata = test_data2)
mse = sum(test_data2$AUD-pred^2)/nrow(test_data2)
mse
skimr::skim(train_data1)
plot(varImp(mod_rf,scale=T),top = 10)
dotplot(resamples(mod_list),metric = "Rsquared")
knitr::opts_chunk$set(echo = FALSE)
#visualize the distribution for each variable
train_data1 %>%
select_if(is.numeric) %>%
gather(var,val) %>%
ggplot(aes(val,group=var)) +
geom_histogram(bins = 30) +
facet_wrap(~var,scales="free",ncol=2)
#visualize the distribution for each variable
train_data1 %>%
select_if(is.numeric) %>%
gather(var,val) %>%
ggplot(aes(val,group=var)) +
geom_histogram(bins = 30) +
facet_wrap(~var,scales="free",ncol=2)
knitr::opts_chunk$set(echo = FALSE)
require(readr)
require(tidyverse)
require(reshape)
require(caret)
require(recipes)
require(pdp)
require(vip)
require(ggplot2)
## Data wrangling
data1 = read_csv("age_dependency_ratio.csv") %>%
select("Country Name", "2008":"2017") %>%
gather(Year, age_dependency_ratio, "2008":"2017")
data2 = read_csv("alcohol use disorder and drug use disorder.csv") %>%
select(-"Code", -"Total population (Gapminder)") %>%
filter(Year == "2008"|Year == "2009"|Year == "2010"|Year == "2011"|Year == "2012"|Year == "2013"|Year ==      "2014"|Year == "2015"|Year == "2016"|Year =="2017")
names(data2) <- c("Country Name", "Year", "AUD", "DUD")
data3 = read_csv("GDP.csv") %>%
select(-"Code") %>%
filter(Year == "2008"|Year == "2009"|Year == "2010"|Year == "2011"|Year == "2012"|Year == "2013"|Year ==      "2014"|Year == "2015"|Year == "2016"|Year =="2017")
names(data3) <- c("Country Name", "Year", "GDP")
data4 = read_csv("GNI.csv") %>%
select("Country Name", "2008":"2017") %>%
gather(Year, GNI, "2008":"2017" )
data5 = read_csv("labor force.csv") %>%
select("Country Name", "2008":"2017") %>%
gather(Year, labor_force, "2008":"2017")
data6 = read_csv("primary school enrollment.csv") %>%
select("Country Name", "2008":"2017") %>%
gather(Year, primary_school_enrollment, "2008":"2017")
data7 = read_csv("refugee population.csv") %>%
select("Country Name", "2008":"2017") %>%
gather(Year, refugee_population, "2008":"2017")
data8 = read_csv("unemployment.csv") %>%
select("Country Name", "2008":"2017") %>%
gather(Year, unemployment, "2008":"2017")
data9 = read_csv("population.csv") %>%
select("Country Name", "2008":"2017") %>%
gather(Year, population, "2008":"2017")
data10 = read_csv("population_male.csv") %>%
select("Country Name", "2008":"2017") %>%
gather(Year, population_male, "2008":"2017")
data11 = read_csv("population_female.csv") %>%
select("Country Name", "2008":"2017") %>%
gather(Year, population_female, "2008":"2017")
data_ml <- Reduce(function(old, new) { merge(old, new, by=c('Country Name', 'Year'), all = TRUE)},
list(data1, data2, data3, data4, data5, data6, data7,
data8, data9, data10, data11)) %>%
mutate(sexratio = population_male / population_female) %>%
na.omit(data_ml)
head(data_ml)
#split the data
index = createDataPartition(data_ml$AUD,p=.75,list=F)
train_data1 = data_ml[index,] # Use 75% of the data as training data
test_data1 = data_ml[-index,] # holdout 25% as test data
dim(train_data1)
dim(test_data1)
skimr::skim(train_data1)
#visualize the distribution for each variable
train_data1 %>%
select_if(is.numeric) %>%
gather(var,val) %>%
ggplot(aes(val,group=var)) +
geom_histogram(bins = 30) +
facet_wrap(~var,scales="free",ncol=2)
sigma = train_data1 %>% select(age_dependency_ratio, AUD, DUD, GDP, sexratio, primary_school_enrollment, refugee_population, unemployment) %>% cor()
ggcorrplot::ggcorrplot(sigma,hc.order = TRUE,outline.col = "white",tl.cex = 5)
data_pred <-
data_ml %>%
select(age_dependency_ratio, AUD, DUD, GDP, GNI, labor_force, population, sexratio, primary_school_enrollment, refugee_population, unemployment )
summarise(data_pred)
# Generate our recipe to preprocess the data
rcp <-
recipe(AUD~.,data = data_pred) %>%
step_range(all_numeric()) %>%  # Normalize scale
prep()
# Apply the recipe to the training and test data
train_data2 <- bake(rcp,new_data = data_pred)
test_data2 <- bake(rcp,new_data = data_pred)
# Cross-validation
set.seed(1988) # set a seed for replication purposes
folds <- createFolds(train_data2$AUD, k = 10) # Partition the data into 10 equal folds
sapply(folds,length)
#set up our validation conditions
control_conditions <-
trainControl(method='cv', # K-fold cross validation
index = folds # The indices for our folds (so they are always the same)
)
# Linear Regression
mod_lm <-
train(AUD ~ .,          # Equation (outcome and everything else)
data=train_data2, # Training data
method = "lm",    # linear model
metric = "RMSE",   # mean squared error
trControl = control_conditions # Cross validation conditions
)
mod_lm
pred_lm <- predict(mod_lm, test_data2)
pred_lm <- data.frame(pred = pred_lm, sexratio = test_data2$sexratio)
# plot for sexratio
ggplot(data = pred_lm) + geom_line(aes(x = sexratio, y = pred)) + geom_point(data = test_data2, aes(x=sexratio, y=AUD))
# K-Nearest Neighbors
mod_knn <-
train(AUD ~ .,           # Equation (outcome and everything else)
data=train_data2,  # Training data
method = "knn",    # K-Nearest Neighbors Algorithm
metric = "RMSE",   # mean squared error
trControl = control_conditions # Cross validation conditions
)
mod_knn
plot(mod_knn)
# Random Forest
mod_rf <-
train(AUD ~ ., # Equation (outcome and everything else)
data=train_data2, # Training data
method = "ranger", # random forest (ranger is much faster than rf)
metric = "RMSE",     # mean squared error
trControl = control_conditions,
importance = 'impurity'
)
mod_rf
plot(mod_rf)
# Model Comparison
# Organize all model imputs as a list.
mod_list <-
list(
lm = mod_lm,
knn = mod_knn,
rf = mod_rf
)
# Resamples allows us to compare model output
resamples(mod_list)
dotplot(resamples(mod_list),metric = "RMSE")
dotplot(resamples(mod_list),metric = "Rsquared")
pred <- predict(mod_rf,newdata = test_data2)
mse = sum(test_data2$AUD-pred^2)/nrow(test_data2)
mse
plot(varImp(mod_rf,scale=T),top = 10)
#visualize the distribution for each variable
train_data1 %>%
select_if(is.numeric) %>%
gather(var,val) %>%
ggplot(aes(val,group=var)) +
geom_histogram(bins = 30) +
facet_wrap(~var,scales="free",ncol=2)
#visualize the distribution for each variable
train_data1 %>%
select_if(is.numeric) %>%
gather(var,val) %>%
ggplot(aes(val,group=var)) +
geom_histogram(bins = 30) +
facet_wrap(~var,scales="free",ncol=2)
#visualize the distribution for each variable
train_data1 %>%
select_if(is.numeric) %>%
gather(var,val) %>%
ggplot(aes(val,group=var)) +
geom_histogram(bins = 30) +
facet_wrap(~var,scales="free",ncol=2)
knitr::opts_chunk$set(echo = TRUE)
getwd(data6)
read_csv(data6)
read_csv(data6.csv)
read_csv("data6.csv")
read_csv("data6.csv")
read_csv("data6.csv")
read_csv("data6.csv")
read_csv("data6.csv")
dat <- read_csv("data6.csv")
dat <- read_csv("data6.csv")
dat <- read_csv("data6.csv")
dat <- read_csv("dat6.csv")
dat <- read_csv("dat6.csv")
head(dat)
dat <- read_csv("dat6.csv")
glimpse(dat)
View(data_ml)
dat <- read_csv("dat6.csv")
glimpse(dat)
ggplot(data=dat6,aes(x='international tourism',y='Country Name')) +
geom_point()
ggplot(data=dat,aes(x='international tourism',y='Country Name')) +
geom_point()
datplot <- filter(Year == "2017")
datplot <- filter(year == "2017")
datplot <- filter('year' == "2017")
require(tidyverse)
datplot <- filter('year' == "2017")
require(tidyverse)
datplot <- filter(dat, 'year' == "2017")
ggplot(data=dataplot,aes(x='international tourism',y='Country Name')) +
geom_point()
require(tidyverse)
datplot <- filter(dat, 'year' == "2017")
ggplot(data=datplot,aes(x='international tourism',y='Country Name')) +
geom_point()
View(datplot)
View(datplot)
require(tidyverse)
datplot <- filter(dat, 'year' == "2016")
ggplot(data=datplot,aes(x='international tourism',y='Country Name')) +
geom_point()
