---
title: "Chu_Yiwei_yc878_finalproject"
author: "Yiwei Chu"
date: "12/2/2019"
output: slidy_presentation
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
```

```{r echo = FALSE, results = 'hide', message = FALSE}
require(readr)
require(tidyverse)
require(reshape)
require(caret)
require(recipes)
require(pdp)
require(vip)
require(ggplot2)
```
## Problem statement and background
- Problem Statement:
In this project, I hope to research percentage of alcohol use disorder population, because it has been a serious social issue and many friends of mine are suffering from the disorder. 
I collected data from worldbank and our world in data, where each row is a country's name data for each year from 2008 to 2017. After cleaning it, it has 1067 rows of observations and 15 columns, and I choose Drug use disorder, Age Dependency Ratio, GDP, GNI, Labor Force, Primary School Enrollment, Refugee Population, Unemployment, Population and sex ratio as predicators. 
I hope to calculate correlation to study the relationship between attributes, the importance of predictors, and create different models(Linear Regression Model, K-Nearest Neighbors Model, Random Forest Model) to predict the percentage of alcohol use disorder population.

- Data Background
- Data sources: World Bank, Our World in Data
- Data variables: AUD, DUD, Age Dependency Ratio, GDP, GNI, Labor Force, Primary School Enrollment, Refugee Population, Unemployment, Population, Male Population, Female Population.
- Data distribution: Most of the data are right-skewed, only the distribution of primary school enrollment data is close to normal distribution.

## Methods/Tools I use and the rational for that use
- Methods
-Data wrangling: I mainly use "select", "mutate", "gather" and "filter" to clean the data and use "merge" to combine all the data frames into one data frame.
- Use 75% data as train data and 25% data as test data
- Supervised Learning(Regression)
Since the outcome is numeric, I use Regression instead of classification. I basiclly use three models.
-Linear Regression
-K-Nearest Neighbors
-Random Forest
After running these models, I examine which model fits best through calculating RMESE and Rsquared, then I calculate the MSE of the best fit model.
- Data visualization
I mainly visualize the distribution of predicators, K-Nearest neighbors model, Random forest model, the relationship between variables and the variable importance. The reason why I want to visualize these is because  that is the most intuitive way, and we can see a lot from the pictures.
- Examine Variable Importance
I use importance function to examine the variable importance to be clear which variable is the most importance when predicating the outcome.
- Tools
(readr), (tidyverse), (reshape), (caret), (recipes), (pdp), (vip), (ggplot2)

```{r, echo = FALSE, results = 'hide', message = FALSE}
## Data wrangling
data1 = read_csv("age_dependency_ratio.csv") %>% 
  select("Country Name", "2008":"2017") %>%
  gather(Year, age_dependency_ratio, "2008":"2017")

data2 = read_csv("alcohol use disorder and drug use disorder.csv") %>%
  select(-"Code", -"Total population (Gapminder)") %>%
  filter(Year == "2008"|Year == "2009"|Year == "2010"|Year == "2011"|Year == "2012"|Year == "2013"|Year ==      "2014"|Year == "2015"|Year == "2016"|Year =="2017")
names(data2) <- c("Country Name", "Year", "AUD", "DUD")
data3 = read_csv("GDP.csv") %>%
  select(-"Code") %>%
  filter(Year == "2008"|Year == "2009"|Year == "2010"|Year == "2011"|Year == "2012"|Year == "2013"|Year ==      "2014"|Year == "2015"|Year == "2016"|Year =="2017")
names(data3) <- c("Country Name", "Year", "GDP")
data4 = read_csv("GNI.csv") %>%
  select("Country Name", "2008":"2017") %>%
  gather(Year, GNI, "2008":"2017" )
data5 = read_csv("labor force.csv") %>%
  select("Country Name", "2008":"2017") %>%
  gather(Year, labor_force, "2008":"2017")
data6 = read_csv("primary school enrollment.csv") %>%
  select("Country Name", "2008":"2017") %>%
  gather(Year, primary_school_enrollment, "2008":"2017")
data7 = read_csv("refugee population.csv") %>%
  select("Country Name", "2008":"2017") %>%
  gather(Year, refugee_population, "2008":"2017")
data8 = read_csv("unemployment.csv") %>%
  select("Country Name", "2008":"2017") %>%
  gather(Year, unemployment, "2008":"2017")
data9 = read_csv("population.csv") %>%
  select("Country Name", "2008":"2017") %>%
  gather(Year, population, "2008":"2017")
data10 = read_csv("population_male.csv") %>%
  select("Country Name", "2008":"2017") %>%
  gather(Year, population_male, "2008":"2017")
data11 = read_csv("population_female.csv") %>%
  select("Country Name", "2008":"2017") %>%
  gather(Year, population_female, "2008":"2017")
data_ml <- Reduce(function(old, new) { merge(old, new, by=c('Country Name', 'Year'), all = TRUE)},
             list(data1, data2, data3, data4, data5, data6, data7, 
                  data8, data9, data10, data11)) %>%
           mutate(sexratio = population_male / population_female) %>%
           na.omit(data_ml) 
           
head(data_ml)
```

```{r echo = FALSE, results = 'hide', message = FALSE}
#split the data
index = createDataPartition(data_ml$AUD,p=.75,list=F) 
train_data1 = data_ml[index,] # Use 75% of the data as training data 
test_data1 = data_ml[-index,] # holdout 25% as test data 

dim(train_data1)
dim(test_data1) 
```

```{r echo = FALSE, results = 'hide', message = FALSE}
skimr::skim(train_data1)
```

```{r, echo = FALSE, results = 'hide', message = FALSE, eval = FALSE, fig.height=10,fig.width=5}
#visualize the distribution for each variable
train_data1 %>% 
  select_if(is.numeric) %>% 
  gather(var,val) %>% 
  ggplot(aes(val,group=var)) +
  geom_histogram(bins = 30) +
  facet_wrap(~var,scales="free",ncol=2)
```

## Visualize the correlation
```{r}
sigma = train_data1 %>% select(age_dependency_ratio, AUD, DUD, GDP, sexratio, primary_school_enrollment, refugee_population, unemployment) %>% cor()
ggcorrplot::ggcorrplot(sigma,hc.order = TRUE,outline.col = "white",tl.cex = 5)
```

```{r echo = FALSE, results = 'hide', message = FALSE}
data_pred <-
  data_ml %>%
  select(age_dependency_ratio, AUD, DUD, GDP, GNI, labor_force, population, sexratio, primary_school_enrollment, refugee_population, unemployment )
summarise(data_pred)
```

```{r echo = FALSE, results = 'hide', message = FALSE}
# Generate our recipe to preprocess the data 
rcp <- 
  recipe(AUD~.,data = data_pred) %>%
  step_range(all_numeric()) %>%  # Normalize scale
  prep()


# Apply the recipe to the training and test data
train_data2 <- bake(rcp,new_data = data_pred)
test_data2 <- bake(rcp,new_data = data_pred) 

```

```{r echo = FALSE, results = 'hide', message = FALSE}
# Cross-validation
set.seed(1988) # set a seed for replication purposes 

folds <- createFolds(train_data2$AUD, k = 10) # Partition the data into 10 equal folds

sapply(folds,length)
```

```{r echo = FALSE, results = 'hide', message = FALSE}
#set up our validation conditions
control_conditions <- 
  trainControl(method='cv', # K-fold cross validation
               index = folds # The indices for our folds (so they are always the same)
  )
```

```{r echo = FALSE, results = 'hide', message = FALSE}
# Linear Regression
mod_lm <-
  train(AUD ~ .,          # Equation (outcome and everything else)
        data=train_data2, # Training data 
        method = "lm",    # linear model
        metric = "RMSE",   # mean squared error
        trControl = control_conditions # Cross validation conditions
  )
mod_lm
pred_lm <- predict(mod_lm, test_data2)
pred_lm <- data.frame(pred = pred_lm, sexratio = test_data2$sexratio)

```
```{r echo=FALSE, results = 'hide', message = FALSE, eval=FALSE}
# plot for sexratio
ggplot(data = pred_lm) + geom_line(aes(x = sexratio, y = pred)) + geom_point(data = test_data2, aes(x=sexratio, y=AUD))
```

```{r echo = FALSE, results = 'hide', message = FALSE}
# K-Nearest Neighbors
mod_knn <-
  train(AUD ~ .,           # Equation (outcome and everything else)
        data=train_data2,  # Training data 
        method = "knn",    # K-Nearest Neighbors Algorithm
        metric = "RMSE",   # mean squared error
        trControl = control_conditions # Cross validation conditions
  )
mod_knn
```

## Plot for mod_knn
```{r}
plot(mod_knn)
```


```{r echo = FALSE, results = 'hide', message = FALSE}
# Random Forest
mod_rf <-
  train(AUD ~ ., # Equation (outcome and everything else)
        data=train_data2, # Training data 
        method = "ranger", # random forest (ranger is much faster than rf)
        metric = "RMSE",     # mean squared error
        trControl = control_conditions,
        importance = 'impurity'
  )
mod_rf
```

## Plot for mod_rf
```{r echo=TRUE}
plot(mod_rf)
```

```{r echo = FALSE, results = 'hide', message = FALSE}
# Model Comparison
# Organize all model imputs as a list.
mod_list <-
  list(
    lm = mod_lm,
    knn = mod_knn,
    rf = mod_rf 
  )

# Resamples allows us to compare model output
resamples(mod_list)
```

## Examine the error across each of the models.
-Linear Regression has the biggest error, while random forest model has the smallest error.
```{r,fig.width=10,fig.height=4}
dotplot(resamples(mod_list),metric = "RMSE") 
```

## Examine the fit across each of the models.
-Random forest model has the biggest Rsquare, meaning that it performs the best. Therefore, we will choose Random forest model.
```{r,fig.width=10,fig.height=4, echo=FALSE}
dotplot(resamples(mod_list),metric = "Rsquared") 
```

- Test the Predictive Accuracy of the Best Model 
```{r echo=TRUE}
pred <- predict(mod_rf,newdata = test_data2)
mse = sum(test_data2$AUD-pred^2)/nrow(test_data2)
mse 
``` 
## Examine the variable importance
-Sex ratio is the most important variable, and Drug use disorder is the second important variable, then age dependency ratio is the third important variable. 
```{r echo=TRUE}
plot(varImp(mod_rf,scale=T),top = 10)
```

## Lessons learned and Plans
- Choosing predicators
The predicators should be less corrlated with each other（Population, Population_male, Population_female）
- Dropping NA or Imputing NA?
We usually don’t drop all the NA easily since NA mean a lot of things. When the data is skewed, we usually use median to fill the NA, and when the data is not skewed, we use mean to fill the numeric NA and mode to fill the NA.
Therefore, my biggest challenge is about the NA. My next step will be analyzing the NA to see the reason behind it and making decisions of dropping it or imputing it.


